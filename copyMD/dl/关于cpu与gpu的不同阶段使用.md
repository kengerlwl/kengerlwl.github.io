---
title: 关于cpu与gpu的不同阶段使用以及变量的存放
top: false
cover: false
toc: true
mathjax: true
date: 2023-03-13 15:27:31
password:
summary:
tags:
- pytorch
- GPU
categories:
- 学术

---



# 描述

最近在自己编写一个深度学习代码的时候想到了一些问题。由此有了一些思考。

情况：

- 我把数据分为了训练集，验证集，测试集
- 由于gpu不够大，而训练集数据以及模型很大，所以一次性只能放一小部分数据batch进入gpu进行训练。
- 这时候，验证集用来筛选出最佳的模型，我选取的是auc值。
- 在**验证集测试模型性能的时候，使用的是CPU进行测试**，所以会很慢，因为验证集一般相对batch还是很大的，不可能放入gpu进行训练。
- 所以才会出现这种训练了半天，中间突然卡一下的情况。





# LSTM中间验证集计算



场景：

- 我在自己编写一个lstm的代码，由于验证集过大了。所以得放到cpu去执行
- 但是lstm老是报错说：所有变量不在同一个设备。



解决：

- 由于lstm有一个隐藏层，hidden，是运行的时候生成的，要自己编写代码，去更改这个隐藏层所在的设备。