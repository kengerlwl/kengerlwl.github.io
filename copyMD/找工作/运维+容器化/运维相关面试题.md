---
title: 运维相关面试题
top: false
cover: false
toc: true
mathjax: true
draft: true
date: 2024-04-11 15:27:31
password:
summary:
tags:
- 运维
categories:
- find JOB

---





# 操作系统

## swap是什么

Linux 的VM（虚拟内存）=RM（物理内存）+SWAP（交换分区）

Swap的大小是由你自己决定的。**Swap是通过硬盘虚拟出来的内存空间**





## **Linux开机自启过程？**



**1，power on 开机**
**2，POST开机自检**
由主板上的[BIOS](https://so.csdn.net/so/search?q=BIOS&spm=1001.2101.3001.7020)程序来完成
**3，BIOS对硬件进行检测**
BIOS：基本输入输出系统，是个人电脑启动时加载的第一个软件。可从CMOS中读写系统设置的具体信息。

**4，boot启动顺序检查**
hard drive 硬盘
cdrom 光驱
removeable device 可移动设备
Network 从网络中的服务器启动
一般从硬盘启动
**5，硬盘**
硬盘里有一个MBR分区
**6，MBR**
主引导记录，MBR是第一个可开机设备的第一个扇区的引导分区块，内包含引导加载程序，电脑开机的时候，计算机系统会主动去执行BIOS这个程序，然后BIOS会分析计算机上的存储设备，硬盘的话，BIOS会到该硬盘里面去读取第一个扇区的MBR位置，MBR里面放着引导加载程序，加载内核文件
**7,groub2引导启动程序**
里面的ext4驱动，可以识别/boot分区里的内容

**8，/boot**
/boot分区里有vmlinuxz 和initramfs执行这两个文件，将其加载到内存
*vmlinuz-4.18.0-147.el8.x86_64 真正的linux内核程序
initramfs-4.18.0-147.el8.x86_64.img --为内核配套的文件系统，存放了很多的驱动*

*注：initramfs文件可以解压：
cpio -idmv < ./initramfs.img*

**9.启动systemd进程**
systemd进程 是linux里的第1个进程
**10，启动对应的运行级别里的服务**

**11，之后进入login登录页面（输入用户名和密码）**



## CPU 的 load和idle的区别是什么？



在Linux系统中，通过top命令可以查看cpu.idle和cpu.load。

![image-20240417201433580](https://raw.githubusercontent.com/kengerlwl/kengerlwl.github.io/master/image/b8003d4e3289cf134b2e95e1215e6485/58e19ae517e1d16c6b09c3c7b4affbbf.png)

**cpu.idle**

**cpu.idle指的是CPU处于空闲状态时间比例**，从时间的角度衡量CPU的空闲程度。

CPU利用率主要分为用户态，系统态和空闲态，分别表示CPU处于用户态执行的时间，系统内核执行的时间，和空闲系统进程执行的时间，三者之和就是CPU的总时间。

**cpu.load**

**cpu.load被定义为在特定时间间隔内运行队列中(在CPU上运行或者等待运行多少进程)的平均进程数**。如果一个进程满足以下条件则其就会位于运行队列中：



**对于cpu.load多少开始出现性能问题，外界有不同的说法，有的认为cpu.load/cores最好不要超过1，有的认为cpu.load/cores最好不要超过3，有的认为cpu.load不超过2*cores-2即可。（具体还是要根据业务来）**



## **零拷贝、浅拷贝、深拷贝**

**零拷贝（Zero-copy）：**

零拷贝是一种优化技术，旨在减少数据在计算机系统内部传输时的拷贝次数，从而提高数据传输效率和系统性能。**在零拷贝中，数据可以在不涉及拷贝的情况下从一个地方传输到另一个地方。这通常通过内核提供的技术实现，如直接内存访问（DMA）或内存映射（mmap）等**。零拷贝技术**常用于网络数据传输**、文件系统和数据库系统等领域，能够减少数据拷贝带来的性能开销。

**浅拷贝（Shallow copy）：**

**浅拷贝是一种拷贝数据的方式，它只复制对象的引用，而不复制对象本身**。这意味着原始对象和浅拷贝后的对象共享相同的内存空间，如果修改了一个对象的属性，另一个对象的属性也会受到影响。在浅拷贝中，通常只复制对象的顶层结构，而不会递归地复制对象的嵌套结构。浅拷贝适用于简单的数据结构，但可能导致数据共享和意外修改的问题。

**深拷贝（Deep copy）：**

**深拷贝是一种拷贝数据的方式，它会递归地复制对象的所有嵌套结构，包括对象本身及其所有子对象**。这样，深拷贝后的对象和原始对象是完全独立的，修改一个对象的属性不会影响另一个对象。深拷贝通常会消耗更多的系统资源，因为需要复制对象的所有数据，但它能够确保对象之间的独立性和数据完整性。深拷贝适用于复杂的数据结构，尤其是包含嵌套结构的情况。



## 多核CPU和多CPU的区别

**主要在于性能和成本**。 

- 多核CPU性能最好，但成本最高；多CPU成本小，便宜，但性能相对较差。
-  多核CPU包含多个处理器，多个CPU也是多个处理器，**前者之间是集成电路，后者之间是传统电路。 多核CPU共用一组内存，数据共享**



## Linux内核参数相关的问题？





## 进程上下文与中断上下文

- 所谓“**进程上下文**”，就是一个进程在执行的时候，**CPU的所有寄存器中的值、进程的状态以及堆栈上的内容**，当内核需要切换到另一个进程时，它需要保存当前进程的所有状态，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时的状态，继续执行。

- “**中断上下文**”，就是硬件通过触发信号，导致内核调用中断处理程序，进入内核空间。这个过程中，**硬件的一些变量和参数也要传递给内核，内核通过这些参数进行中断处理**。中断上下文，其实也**可以看作就是硬件传递过来的这些参数和内核需要保存的一些其他环境**（主要是当前被中断的进程环境）。









## TCP网络连接的状态有几种？

- CLOSED: 初始状态。
- LISTEN: 服务器端的某个SOCKET处于监听状态，可以接受连接。
- SYN_SENT: 客户端执行CONNECT连接时发送SYN报文，等待服务端确认。
- SYN_RCVD: 服务端接受到SYN报文的中间状态，一般很短暂。
- **ESTABLISHED: 连接已建立。**
- FIN_WAIT_1: 请求终止连接，等待对方的FIN报文。
- FIN_WAIT_2: 半连接，一方请求关闭连接但还有数据传输需求。
- **TIME_WAIT: 收到对方的FIN报文并发送ACK报文后等待一段时间后可回到CLOSED状态。**
- CLOSING: 双方几乎同时关闭连接，表示双方都在关闭连接。
- **CLOSE_WAIT: 等待关闭状态，对方已关闭连接但还有数据需要发送**。
- LAST_ACK: 发送FIN报文后等待对方的ACK报文，收到后进入CLOSED状态。





## 什么情况用户态进入内核 具体哪些操作呢

- `系统调用`：其实系统调用本身就是中断，但是软件中断，跟硬中断不同。
- `异常`： 当CPU正在执行运行在用户态的程序时，突然发生某些预先不可知的异常事件，这个时候就会触发从当前用户态执行的进程转向内核态执行相关的异常事件，典型的如`缺页异常`。
- `外设中断（硬中断）`：当外围设备完成用户的请求操作后，会像CPU发出中断信号，此时，CPU就会暂停执行下一条即将要执行的指令，转而去执行中断信号对应的处理程序，如果先前执行的指令是在用户态下，则自然就发生从用户态到内核态的转换。

**为什么不要频繁的设计两个状态的切换**

- 涉及频繁的进程上下文切换
- IO设备到内核中读取数据，导致数据到内核态中和到用户态中被拷贝了两次（**从IO设备到内核缓冲区的拷贝**：**从内核缓冲区到用户态的拷贝**）



## kill-9算什么

**kill -9则是强制终止进程**，相当于发送信号9，不管进程是否想要退出，都会被迫停止运行。



## linux 进程内存结构

进程占用的用户空间按照访问属性一致的地址空间存放在一起，划分成了5个不同的内存区域：

1. **代码段（Text Segment）**：**存放可执行文件的操作指令**，是程序在内存中的镜像。代码段只允许读取操作，不可写入，以防止在运行时被非法修改。

2. **数据段（Data Segment）**：存放可执行文件中已**初始化的全局变量**，即程序静态分配的变量和全局变量。

3. **BSS段**：包含了程序中**未初始化的全局变量**，在内存中全部置零。

4. **堆（Heap（堆比栈快））**：用于**存放进程运行中被动态分配的内存段**。堆的大小不固定，可以动态扩张或缩减。当进程调用malloc等函数分配内存时，新分配的内存被动态添加到堆上；当利用free等函数释放内存时，被释放的内存从堆中被剔除。

5. **栈（Stack）**：**用于存放程序临时创建的局部变量，即函数中定义的变量**。在函数被调用时，其参数被压入栈中，并在函数调用结束后，返回值也被存放回栈中。栈的先进先出特性使其方便用于保存和恢复调用现场，因此栈常用于函数调用和控制流程的临时数据存储。





## linux系统内存结构





## 云原生的理解

云原生是一种软件架构的方法，旨在利用云服务的优势来构建、部署和运行应用程序。**它强调容器化、微服务、自动化和持续交付**









## Linux内存中Cache和Buffer的区别

**内存buffer\**\**与cache区别？**

**Buffer**将数据写入到内存里，这个数据的内存空间在Linux系统里一般被称为缓冲区(buffer)，写入到内存buffer缓冲区，写缓冲。
**Cache**从内存读取数据，这个数据的内存空间在Linux系统里一般被称为缓存区(cache),从内存cache读取，缓存区，读缓存。
**Cache一般用于读取数据，Buffer一般用于写入数据。内存一般有两个参数Memory Cache和Memory Buffe**r。
Linux 命令 free 命令查看的是指的是Memory Cache 不是 CPU Cache.









## linux删除文件后没有释放空间

在*Linux*或者*Unix*系统中，通过*rm*或者文件管理器删除文件将会从文件系统的目录结构上解除链接*(unlink).*然而如果文件是被***打开的（有一个进程正在使用），那么进程将仍然可以读取该文件，磁盘空间也一直被占用。而我删除的是*oracle*的告警*log*文件***删除的时候文件应该正在被使用



**解决办法**

首先获得一个已经被删除但是仍然被应用程序占用的文件列表，如下所示：

```
[root@ticketb ~]# lsof |grep deleted
oracle  12639 oracle  5w   REG       253,0     648   215907 /home/oracle/admin/dbticb/udump/dbticb_ora_12637.trc (deleted)
oracle  12639 oracle  6w   REG       253,0 16749822091   215748 /home/oracle/admin/dbticb/bdump/alert_dbticb.log (deleted)
```

如何让进程释放呢？

 

一种方法是*kill*掉相应的进程，或者停掉使用这个文件的应用，让*os*自动回收磁盘空间

我这个环境有很多进程在使用的这个文件，停掉进程有点麻烦，再有就是风险很大

 

当*linux*打开一个文件的时候*,Linux*内核会为每一个进程在*/proc/* 『*/proc/nnnn/fd/*目录（*nnnn*为*pid*）』建立一个以其*pid
*为名的目录用来保存进程的相关信息，而其子目录*fd*保存的是该进程打开的所有文件的*fd*（*fd*：*file descriptor*）。

*kill*进程是通过截断*proc*文件系统中的文件可以强制要求系统回收分配给正在使用的的文件。*
*这是一项高级技术，仅到管理员确定不会对运行中的进程造成影响时使用。应用程序对这种方*
*式支持的并不好，当一个正在使用的文件被截断可能会引发不可预知的问题





## LSOF命令 

*lsof*全名*list opened files*，也就是列举系统中已经被打开的文件。我们都知道，*linux*环境中，任何事物都是文件，
*设备是文件，目录是文件，甚至*sockets*也是文件。所以，用好*lsof*命令，对日常的*linux*管理非常有帮助。



## 排查定位linux系统的性能瓶颈

**CPU，内存，磁盘，网络带宽以及其他设备**



## NUMA(Non-Uniform Memory Access)架构

即非一致性内存访问，是一种关于多个CPU如何访问内存的架构模型



![image-20240417202651175](https://raw.githubusercontent.com/kengerlwl/kengerlwl.github.io/master/image/b8003d4e3289cf134b2e95e1215e6485/5804e68ed9872eb213c2d5748e678da3.png)

**在NUMA架构中，将CPU划分到多个NUMA Node中，每个Node有自己独立的内存空间和PCIE总线系统。各个CPU间通过QPI总线进行互通。**

CPU访问不同类型节点内存的速度是不相同的**，访问本地节点的速度最快，访问远端节点的速度最慢，即访问速度与节点的距离有关，距离越远访，问速度越慢，所以叫做非一致性内存访问**，这个访问内存的距离我们称作Node Distance。



## 内存（memory）泄露与句柄（socket）泄露

**内存泄露**

**内存泄漏是指程序在动态分配内存后，未释放或者未能完全释放该内存空间的情况**。这样会导致内存不断被占用，进而导致程序性能下降、甚至崩溃等问题。

**比如java的`theadLocal`**

注意区分：内存溢出：指分配的内存空间不足以满足当前需要，导致程序崩溃。



**句柄泄露**

1. **文件句柄泄露**：在程序中打开文件后，如果没有正确关闭文件句柄，就会导致文件句柄泄露。例如，在一个循环中反复打开文件而未关闭，最终会耗尽系统的文件描述符资源。
2. **网络连接句柄泄露**：在网络编程中，如果程序创建了网络连接但未正确关闭连接句柄，就会导致网络连接句柄泄露。例如，在一个长期运行的服务器程序中，未正确释放客户端连接可能会导致连接句柄泄露，最终耗尽系统的网络资源，导致服务不可用或性能下降。



## linux查看大文件

**[vim](https://so.csdn.net/so/search?q=vim&spm=1001.2101.3001.7020)和cat 会消耗比较多的内存和cpu资源，导致系统死机或者卡顿，因此读取大文件不建议使用；**
more和less 不会消耗特别多的内存和cpu资源。





## linux虚拟文件系统

概括地讲，VFS 有两个作用：

1. 处理与 Unix 标准文件系统相关的所有系统调用
2. 为各种文件系统提供一个通用的接口

**参考**

[linux的文件系统的作用,Linux下的虚拟文件系统究竟起到什么作用?-CSDN博客](https://blog.csdn.net/weixin_35879493/article/details/116864069)





## fd文件描述符



**fd 是 File descriptor 的缩写，中文名叫做：文件描述符**（ fd 句柄）。文件描述符是一个非负整数，本质上是一个索引值（这句话非常重要）。**由于linux一切皆文件，所以这个还挺重要，网络io磁盘io都是**

用户使用系统调用 open 或者 creat 来打开或创建一个文件，用户态得到的结果值就是 fd ，后续的 IO 操作全都是用 fd 来标识这个文件，可想而知内核做的操作并不简单，我们接下来就是要揭开这层面纱。



# 网络

## 什么是BGP

BGP是边界网关协议Border Gateway Protocol的简称，是用来连接Internet上的独立系统的路由选择协议。BGP主要用于互联网AS（自治系统）之间的互联，BGP的最主要功能在于控制路由的传播和选择最好的路由

## 解释一下RIP、BGP、IGP协议








## 负载均衡原理

[LVS负载均衡原理及实现（DR、TUN模式）_tun实现是什么-CSDN博客](https://blog.csdn.net/yrx420909/article/details/104423334)

LVS：是基于四层的转发（**抗负载均衡能力强**）

HAproxy：是基于四层和七层的转发，是专业的代理服务器

Nginx：是WEB服务器，缓存服务器，又是反向代理服务器，可以做七层的转发

区别：**LVS由于是基于四层的转发所以只能做端口的转发、而基于URL的、基于目录的这种转发LVS就做 不了**

工作选择：HAproxy和Nginx由于可以做七层的转发，所以URL和目录的转发都可以做，在很大并发量的 时候我们就要选择LVS，像中小型公司的话并发量没那么大，选择HAproxy或者Nginx足已，由于 HAproxy由是专业的代理服务器，配置简单，所以中小型企业推荐使用HAproxy





### K8S的代理原理

kube-proxy 支持多种负载均衡模式，包括以下几种：

1. **用户空间代理模式（userspace）**：kube-proxy 在每个节点上启动一个 userspace 网络代理进程，通过修改每个节点上的 **iptables 规则，将流量转发到对应的 Service 后端 Pod**。
2. **IPVS代理模式（IPVS）**：kube-proxy 可以使用 IPVS（IP Virtual Server）技术来实现负载均衡。在这种模式下，kube-proxy 会创建 IPVS 规则和服务转发表，**利用 Linux 内核的 IPVS 功能来进行负载均衡**。
3. **直接连接模式（Direct）**：kube-proxy 也可以使用直接连接模式，即直接将流量转发到 Service 对应的 Pod 的 IP 地址上，而不通过额外的代理层。



## 简述 LVS 的工作模式及其工作过程

LVS 有三种负载均衡的模式，分别是 VS/NAT（nat 模式）、VS/DR（路由模式）、VS/TUN（隧道模式）。

- **NAT 模式**（VS-NAT）
  - `原理`：首先负载均衡器接收到客户的请求数据包时，根据调度算法决定将请求发送给哪个后端的真实服务器（RS）。然后负载均衡器就把客户端发送的请求数据包的目标 IP 地址及端口改成后端真实服务器的 IP 地址（RIP）。真实服务器响应完请求后，**查看默认路由，把响应后的数据包发送给负载均衡器**，负载均衡器在接收到响应包后，**把包的源地址改成虚拟地址（VIP）然后发送回给客户端**。
  - `优点`：集群中的服务器可以使用任何支持 TCP/IP 的操作系统，只要负载均衡器有一个合法的 IP 地址。
  - `缺点`：扩展性有限，当服务器节点增长过多时，由于所有的请求和应答都需要经过负载均衡器，因此负载均衡器将成为整个系统的瓶颈。
- IP 隧道模式（VS-TUN）
  - `原理`：首先负载均衡器接收到客户的请求数据包时，根据调度算法决定将请求发送给哪个后端的真实服务器（RS）**。然后负载均衡器就把客户端发送的请求报文封装一层 IP 隧道（T-IP）转发到真实服务器（RS）。真实服务器响应完请求后，查看默认路由，把响应后的数据包直接发送给客户端，不需要经过负载均衡器。**
  - `优点`：负载均衡器只负责将请求包分发给后端节点服务器，而 RS 将应答包直接发给用户。所以，减少了负载均衡器的大量数据流动，负载均衡器不再是系统的瓶颈，也能处理很巨大的请求量。
  - `缺点`：隧道模式的 RS 节点需要合法 IP，这种方式需要所有的服务器支持“IP Tunneling”。
- 直接路由模式（VS-DR）
  - `原理`：首先负载均衡器接收到客户的请求数据包时，根据调度算法决定将请求发送给哪个后端的真实服务器（RS）。然后负载均衡器就把客户端发送的请求数据包的目标 MAC 地址改成后端真实服务器的 MAC 地址（R-MAC）。真实服务器响应完请求后，查看默认路由，把响应后的数据包直接发送给客户端，不需要经过负载均衡器。
  - `优点`：负载均衡器只负责将请求包分发给后端节点服务器，而 RS 将应答包直接发给用户。所以，减少了负载均衡器的大量数据流动，负载均衡器不再是系统的瓶颈，也能处理很巨大的请求量。
  - `缺点`：需要负载均衡器与真实服务器 RS 都有一块网卡连接到同一物理网段上，必须在同一个局域网环境。





# K8S





## K8S集群规模？三台机器的作用？master+worker







## proxy部署在哪些节点一般













# 其他业务架构题



## 数据库表里有100万条数据，想要删除80万条数据，但是因为锁的原因，删除很慢，现在想要快速删除怎么办











# 智力题



1 简单做个自我介绍

2 说一个你觉得最有挑战的项目

3 说一下难点在哪里

4 其他人是怎么做的

5 你觉的你比别人做的好的地方在哪里

6 xxx技术你是怎么思考的为什么，要什么要用

7 你平时是否关注业界哪些方向

8 你是否在写写博客什么的

9 说一下你的职业规划和思考









# ref

[运维最常见100道面试题 - 知乎](https://zhuanlan.zhihu.com/p/569207604?utm_psn=1763945503203880960)





















