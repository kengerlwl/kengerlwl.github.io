<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Pytorch - 标签 - Kenger`s Blog</title>
        <link>https://kengerlwl.github.io/tags/pytorch/</link>
        <description>Pytorch - 标签 - Kenger`s Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>kengerlwl@qq.com (kenger)</managingEditor>
            <webMaster>kengerlwl@qq.com (kenger)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sat, 26 Oct 2024 15:27:31 &#43;0000</lastBuildDate><atom:link href="https://kengerlwl.github.io/tags/pytorch/" rel="self" type="application/rss+xml" /><item>
    <title>tokenizer使用指北</title>
    <link>https://kengerlwl.github.io/tokenizer%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8C%97/</link>
    <pubDate>Sat, 26 Oct 2024 15:27:31 &#43;0000</pubDate>
    <author>kenger</author>
    <guid>https://kengerlwl.github.io/tokenizer%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8C%97/</guid>
    <description><![CDATA[背景 文本到向量需要有个中间层，用来将文本分词，然后将不同的文本编码为序号。 例如一个文本 i am your father. 就应该分词为四个单词，然后其中首位还应该加入首]]></description>
</item>
<item>
    <title>大模型底层八股</title>
    <link>https://kengerlwl.github.io/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%95%E5%B1%82%E5%85%AB%E8%82%A1/</link>
    <pubDate>Sun, 18 Aug 2024 15:27:31 &#43;0000</pubDate>
    <author>kenger</author>
    <guid>https://kengerlwl.github.io/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%95%E5%B1%82%E5%85%AB%E8%82%A1/</guid>
    <description><![CDATA[Transformer八股 为什么在Transformer模型中使用Layer Normalization（Layer Norm）而不是Batch]]></description>
</item>
<item>
    <title>大模型token压缩</title>
    <link>https://kengerlwl.github.io/%E5%A4%A7%E6%A8%A1%E5%9E%8Btoken%E5%8E%8B%E7%BC%A9/</link>
    <pubDate>Wed, 14 Aug 2024 15:27:31 &#43;0000</pubDate>
    <author>kenger</author>
    <guid>https://kengerlwl.github.io/%E5%A4%A7%E6%A8%A1%E5%9E%8Btoken%E5%8E%8B%E7%BC%A9/</guid>
    <description><![CDATA[背景 最近在大模型推理方面遇到了瓶颈，需要进一步优化性能，因此决定记录一下这方面的研究。 Tokens 压缩旨在减少语言模型处理的文本量，以提高效率和泛化能]]></description>
</item>
<item>
    <title>自部署大模型实验细节</title>
    <link>https://kengerlwl.github.io/%E8%87%AA%E9%83%A8%E7%BD%B2%E5%A4%A7%E6%A8%A1%E5%9E%8B/</link>
    <pubDate>Tue, 13 Aug 2024 15:27:31 &#43;0000</pubDate>
    <author>kenger</author>
    <guid>https://kengerlwl.github.io/%E8%87%AA%E9%83%A8%E7%BD%B2%E5%A4%A7%E6%A8%A1%E5%9E%8B/</guid>
    <description><![CDATA[huggingface 换源 1 export HF_ENDPOINT=https://hf-mirror.com 下载 1 2 3 4 5 6 7 8 9 10 nohup huggingface-cli download --resume-download Qwen/Qwen-72B-Chat-Int4 --local-dir ./Qwen-72B-Chat-Int4 &gt; 72b.log &amp; huggingface-cli download --resume-download Qwen/Qwen-14B --local-dir ./Qwen-14B huggingface-cli download --resume-download Qwen/Qwen2-7B-Instruct --local-dir ./Qwen-7B huggingface-cli download --resume-download Qwen/Qwen1.5-14B-Chat --local-dir ./Qwen1.5-14B 启动 vllm api 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20]]></description>
</item>
<item>
    <title>大模型agent框架调研</title>
    <link>https://kengerlwl.github.io/%E5%A4%A7%E6%A8%A1%E5%9E%8Bagent%E6%A1%86%E6%9E%B6%E8%B0%83%E7%A0%94/</link>
    <pubDate>Thu, 25 Jul 2024 14:27:31 &#43;0000</pubDate>
    <author>kenger</author>
    <guid>https://kengerlwl.github.io/%E5%A4%A7%E6%A8%A1%E5%9E%8Bagent%E6%A1%86%E6%9E%B6%E8%B0%83%E7%A0%94/</guid>
    <description><![CDATA[背景 最近需要用到这玩意儿，但是我目前只知道langchain等框架，对市场缺乏一个调研。 需要做一个技术选型。 实际上：agent，本质上就是一]]></description>
</item>
<item>
    <title>RLHF算法</title>
    <link>https://kengerlwl.github.io/rlhf/</link>
    <pubDate>Tue, 23 Jul 2024 15:27:31 &#43;0000</pubDate>
    <author>kenger</author>
    <guid>https://kengerlwl.github.io/rlhf/</guid>
    <description><![CDATA[背景 PPO(Proximal Policy Optimization)近端策略优化算法 它属于策略梯度方法的一种，旨在通过限制新策略和旧策略之间的差异来稳定训练过程。PPO通过引]]></description>
</item>
<item>
    <title>大模型system Prompt为什么重要</title>
    <link>https://kengerlwl.github.io/%E5%A4%A7%E6%A8%A1%E5%9E%8Bsystem-prompt%E4%B8%BA%E4%BB%80%E4%B9%88%E9%87%8D%E8%A6%81/</link>
    <pubDate>Tue, 23 Jul 2024 15:27:31 &#43;0000</pubDate>
    <author>kenger</author>
    <guid>https://kengerlwl.github.io/%E5%A4%A7%E6%A8%A1%E5%9E%8Bsystem-prompt%E4%B8%BA%E4%BB%80%E4%B9%88%E9%87%8D%E8%A6%81/</guid>
    <description><![CDATA[背景 一直知道这玩意儿，也知道一部分其底层原理，但是没有实际深究过，决定mark一下。 大模型的记忆原理 从计算机科学的角度来看，最好将LLM的推]]></description>
</item>
<item>
    <title>大模型相关常见问题概念</title>
    <link>https://kengerlwl.github.io/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9B%B8%E5%85%B3%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%A6%82%E5%BF%B5/</link>
    <pubDate>Tue, 23 Jul 2024 15:27:31 &#43;0000</pubDate>
    <author>kenger</author>
    <guid>https://kengerlwl.github.io/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9B%B8%E5%85%B3%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%A6%82%E5%BF%B5/</guid>
    <description><![CDATA[背景 有些东西，名词，经常听见，也大概知道是什么意思，但是就是总记不住，列个case。 幻觉 **如果AI模型所生成输出没有任何已知事实的支持，幻]]></description>
</item>
<item>
    <title>大模型自部署调查</title>
    <link>https://kengerlwl.github.io/%E8%87%AA%E9%83%A8%E7%BD%B2%E5%B9%B6%E5%8F%91%E8%B0%83%E6%9F%A5/</link>
    <pubDate>Tue, 23 Jul 2024 15:27:31 &#43;0000</pubDate>
    <author>kenger</author>
    <guid>https://kengerlwl.github.io/%E8%87%AA%E9%83%A8%E7%BD%B2%E5%B9%B6%E5%8F%91%E8%B0%83%E6%9F%A5/</guid>
    <description><![CDATA[自部署并发调查 由于我们的模型可能需要用到自己的第三方模型，因此需要自己部署。 一个是自己部署，自己维护可靠性，在一站式不成熟的情况下，避免和第]]></description>
</item>
<item>
    <title>LoRA微调原理解读，及相关经验</title>
    <link>https://kengerlwl.github.io/lora%E5%BE%AE%E8%B0%83%E5%8E%9F%E7%90%86%E8%A7%A3%E8%AF%BB/</link>
    <pubDate>Tue, 28 May 2024 15:27:31 &#43;0000</pubDate>
    <author>kenger</author>
    <guid>https://kengerlwl.github.io/lora%E5%BE%AE%E8%B0%83%E5%8E%9F%E7%90%86%E8%A7%A3%E8%AF%BB/</guid>
    <description><![CDATA[介绍 LoRA属于PEFT。一种利用微调训练少量参数，来达到全量微调的效果的技术。 在实际工程中非常常用。 文本主要将LoRA原理以及为什么LoR]]></description>
</item>
</channel>
</rss>
